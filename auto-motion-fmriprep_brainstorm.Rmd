---
title: "auto-motion-fmriprep exploration"
author: "Dani Cosme"
date: "5/6/2018"
output:
  html_document:
    code_folding: hide
    highlight: tango
    theme: united
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = FALSE)
```

# load packages and config file
```{r, warning=FALSE, message=FALSE}
osuRepo = 'http://ftp.osuosl.org/pub/cran/'

if(!require(tidyverse)){
  install.packages('tidyverse',repos=osuRepo)
}
if(!require(caret)){
  install.packages('caret',repos=osuRepo)
}
if(!require(caTools)){
  install.packages('caTools',repos=osuRepo)
}
if(!require(reshape2)){
  install.packages('reshape2',repos=osuRepo)
}
if(!require(PRROC)){
  install.packages('PRROC',repos=osuRepo)
}


library(purrr) # for functional programming (map)
library(pROC) # for AUC calculations
library(doParallel)
library(DMwR) # for smote implementation

# source the config file
source('config.R')
```

# load confound files
```{r, message=FALSE}
file_list = list.files(confoundDir, pattern = 'confounds.tsv', recursive = TRUE)

if (!file.exists("~/Documents/code/auto-motion-fmriprep/tag_tds.csv")) {
  for (file in file_list){
    # if the merged dataset doesn't exist, create it
    if (!exists('dataset')){
      filePattern = paste(subPattern, wavePattern, taskPattern, runPattern, 'bold_confounds.tsv', sep = "_")
      dataset = read_tsv(paste0(confoundDir, file)) %>% 
        mutate(file = file) %>%
        extract(file, c('subjectID', 'wave', 'task', 'run'),
                file.path('.*', 'sub-.*','ses-wave.*', 'func', filePattern)) %>%
        mutate(wave = as.integer(wave),
               run = as.integer(run),
               stdDVARS = as.numeric(ifelse(stdDVARS %in% "n/a", NA, stdDVARS)),
               `non-stdDVARS` = as.numeric(ifelse(`non-stdDVARS` %in% "n/a", NA, `non-stdDVARS`)),
               `vx-wisestdDVARS` = as.numeric(ifelse(`vx-wisestdDVARS` %in% "n/a", NA, `vx-wisestdDVARS`)),
               FramewiseDisplacement = as.numeric(ifelse(FramewiseDisplacement %in% "n/a", NA, FramewiseDisplacement)),
               volume = row_number()) %>%
        select(subjectID, wave, task, run, volume, everything())
    }
  
    # if the merged dataset does exist, append to it
    else {
      filePattern = paste(subPattern, wavePattern, taskPattern, runPattern, 'bold_confounds.tsv', sep = "_")
      tmp = read_tsv(paste0(confoundDir, file)) %>% 
        mutate(file = file) %>%
        extract(file, c('subjectID', 'wave', 'task', 'run'),
                file.path('sub-.*','ses-wave.*', 'func', filePattern)) %>%
        mutate(wave = as.integer(wave),
               run = as.integer(run),
               stdDVARS = as.numeric(ifelse(stdDVARS %in% "n/a", NA, stdDVARS)),
               `non-stdDVARS` = as.numeric(ifelse(`non-stdDVARS` %in% "n/a", NA, `non-stdDVARS`)),
               `vx-wisestdDVARS` = as.numeric(ifelse(`vx-wisestdDVARS` %in% "n/a", NA, `vx-wisestdDVARS`)),
               FramewiseDisplacement = as.numeric(ifelse(FramewiseDisplacement %in% "n/a", NA, FramewiseDisplacement)),
               volume = row_number()) %>%
        select(subjectID, wave, task, run, volume, everything())
      dataset = bind_rows(dataset, tmp)
      rm(tmp)
    }
  write.csv(dataset, "~/Documents/code/auto-motion-fmriprep/tag_tds.csv", row.names = FALSE)
  }
} else {
  dataset = read.csv("~/Documents/code/auto-motion-fmriprep/tag_tds.csv", stringsAsFactors = FALSE)
}

dataset = dataset %>%
  mutate(sub.run = paste(subjectID, task, run, sep = "_"))
```

# load hand coded data and merge
```{r}
coded.tds = read.csv("~/Documents/code/auto-motion-fmriprep/tds_artifacts.csv") %>%
  extract(run, c("task", "run"), "([a-z]+)([0-9]{1})") %>%
  mutate(run = as.integer(run),
         sub.run = paste(subjectID, task, run, sep = "_"),
         subjectID = as.character(subjectID),
         no.artifacts = ifelse(intensity == 0 & striping == 0, 1, NA)) %>%
  select(-fsl.volume)

coded.tag = read.csv("~/Documents/code/auto-motion-fmriprep/tag_artifacts.csv") %>%
  extract(run, c("task", "run"), "([A-Z]+)([0-9]{1})") %>%
  mutate(run = as.integer(run),
         sub.run = paste(subjectID, task, run, sep = "_"),
         volume = fsl.volume + 1) %>%
  select(-fsl.volume) 

coded = bind_rows(coded.tag, coded.tds)

sub_run = unique(coded$sub.run)

joined = left_join(dataset, coded, by = c("subjectID", "task", "run", "volume", "sub.run")) %>%
  mutate(artifact = ifelse(striping == 2, 1, 0),
         artifact = ifelse(is.na(artifact), 0, artifact),
         X.diff = X - lag(X),
         Y.diff = Y - lag(Y),
         Z.diff = Z - lag(Z),
         RotX.diff = RotX - lag(RotX),
         RotY.diff = RotX - lag(RotY),
         RotZ.diff = RotX - lag(RotZ)) %>%
  filter(sub.run %in% sub_run) %>%
  select(subjectID, wave, task, run, volume, artifact, striping, intensity, everything())
```

# visualize
## distributions
```{r, fig.width = 10, fig.height = 15}
data.plot = joined %>%
  gather(feature, value, -c(subjectID, wave, task, run, volume, artifact, striping, intensity, sub.run, no.artifacts)) %>%
  filter(!grepl("Cosine|Steady", feature))

ggplot(data.plot, aes(1, value)) +
  geom_boxplot() +
  geom_jitter(alpha = .02) + 
  facet_wrap(~feature, scales = "free", ncol = 5) + 
  theme_minimal()

ggplot(data.plot, aes(value)) + 
  geom_density(fill = wesanderson::wes_palette("Zissou1", 1, "continuous")) +
  facet_wrap(~feature, scales = "free", ncol = 5) + 
  theme_minimal()
```

## scatter plots
```{r, fig.width=30, fig.height=30, warning=FALSE, error=FALSE, message=FALSE}
p = joined %>%
  select(-c(subjectID, wave, task, run, volume, no.artifacts, sub.run, starts_with("NonSteady"), starts_with("Cosine"))) %>%
  mutate(artifact = as.factor(artifact)) %>%
  ggpairs(aes(colour = artifact, alpha = 0.01)) +
    theme_minimal()
ggsave(p, file = 'correlations.png', height = 30, width = 30)
```

## correlate confounds
```{r, fig.width=12, fig.height=12}
# define color palette
palette = c("#0071CF", "#FFD700", "#E2261C")

# subset and matrix-ify
dataset.corr = joined %>%
  select(-c(subjectID, wave, task, run, volume, no.artifacts, striping, intensity, sub.run, starts_with("NonSteady"), starts_with("Cosine"))) %>%
  cor(., use = "pairwise.complete.obs") %>%
  melt(.)

# plot the data
ggplot(dataset.corr, aes(as.factor(Var2), as.factor(Var1), fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = palette[1], high = palette[3], mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
   name = "correlation") +
  labs(x = "",
       y = "") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1)) + 
  geom_text(aes(label = round(value,1)), size = 2.5)
```

## visualize confounds on a subject level
```{r, fig.width = 15, fig.height = 40} 
subs = unique(joined$subjectID)[1:10]

data.sub = data.plot %>%
  mutate(sort.order = ifelse(grepl("X|Y|Z|Rot|Displacement", feature), 1,
                      ifelse(grepl("DVARS", feature), 2,
                      ifelse(grepl("CSF|WhiteMatter|Signal", feature), 3,
                      ifelse(grepl("Comp", feature), 4, NA))))) %>%
  filter(subjectID %in% subs)

nada = data.sub %>% 
  group_by(subjectID) %>%
    do({
      plot = ggplot(., aes(volume, value)) + 
        geom_line(aes(color = as.factor(sort.order)), size = .25, show.legend = FALSE) +
        facet_grid(reorder(feature, sort.order) ~ task + run, scales = "free") +
        scale_color_manual(values = wesanderson::wes_palette("Zissou1", 4, type = "continuous")) +
        labs(title = .$subjectID[[1]]) +
        theme_minimal()
      print(plot)
      ggsave(plot, file = paste0(plotDir,.$subjectID[[1]],'.pdf'), height = 40, width = 15)
      data.frame()
    })
```

# questions
* Are the values meaningful across participants and runs? Or should they be scaled within subject and run?
* How are rp features defined? From first volume or volume-to-volume?
* aCompCor = signal associated with physiology
* DVARS
  * STD --> more interpretable across subjects

# describe classes
```{r}
table(joined$artifact) / nrow(joined)
```

# machine learning
## split the data 
```{r}
set.seed(101) 
ml.data = joined %>%
  select(-c(subjectID, wave, task, run, volume, no.artifacts, sub.run, striping, intensity, starts_with("NonSteady"), starts_with("Cosine"))) %>%
  mutate(artifact = as.factor(ifelse(artifact == 1, "yes", "no")))

# replace NAs with 0
ml.data[is.na(ml.data)] = 0

# subset dataset into development and holdout samples
sample.dev = sample.split(ml.data$artifact, SplitRatio = .8)
dev = subset(ml.data, sample.dev == TRUE)
holdout = subset(ml.data, sample.dev == FALSE)

# subset development sample into training and testing sets
sample = sample.split(dev$artifact, SplitRatio = .75)
training = subset(dev, sample == TRUE)
testing = subset(dev, sample == FALSE)
```

Classifiers to try
* AdaBoost Classification Trees
* Boosted Classification Trees
* Random forest
* regularlized logistic regression
* SVM
* Gradient boosted machine ()

Resources
[https://rstudio-pubs-static.s3.amazonaws.com/299602_6834adf3be1548a1b5c04a45c7d79c77.html](https://rstudio-pubs-static.s3.amazonaws.com/299602_6834adf3be1548a1b5c04a45c7d79c77.html)
[http://dpmartin42.github.io/posts/r/imbalanced-classes-part-2](http://dpmartin42.github.io/posts/r/imbalanced-classes-part-2)
[https://shiring.github.io/machine_learning/2017/04/02/unbalanced](https://shiring.github.io/machine_learning/2017/04/02/unbalanced)
[https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)
[https://elitedatascience.com/imbalanced-classes](https://elitedatascience.com/imbalanced-classes)
[https://www.svds.com/learning-imbalanced-classes/](https://www.svds.com/learning-imbalanced-classes/)
[https://www.r-bloggers.com/handling-class-imbalance-with-r-and-caret-an-introduction/](https://www.r-bloggers.com/handling-class-imbalance-with-r-and-caret-an-introduction/)

Terminology
* recall = percent of truly positive instances that were classified as such
* precision = percent of positive classifications that are truly positive

Other things
* probability threshold
* class weights
* kappa
* run models with only FD, DVARS, WM, CSF and compare
* Compare plots with current standards for thresholding (e.g. 1mm)

# brainstorming
### SVM
```{r}
# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial SVM
timestamp()
orig_svm = train(artifact ~ .,
                 data = training,
                 method = "svmRadial",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(orig_svm, "orig_svm.rds")

# recycle seeds
ctrl$seeds = orig_svm$control$seeds

# run down-sampled model
ctrl$sampling = "down"
ctrl$repeats = 10

timestamp()
down_svm = train(artifact ~ .,
                 data = training,
                 method = "svmRadial",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(down_svm, "models/down_svm.rds")

# run up-sampled model
ctrl$sampling = "up"
ctrl$repeats = 5

timestamp()
up_svm = train(artifact ~ .,
                 data = training,
                 method = "svmRadial",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(up_svm, "models/up_svm.rds")

# smote
ctrl$sampling = "smote"
ctrl$repeats = 5

timestamp()
smote_svm = train(artifact ~ .,
                 data = training,
                 method = "svmRadial",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(smote_svm, "models/smote_svm.rds")

# stop parallelization
stopCluster(cl)
```

### boosted logistic regression
```{r}
# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial rf
timestamp()
orig_log = train(artifact ~ .,
                 data = training,
                 method = "LogitBoost",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(orig_log, "models/orig_log.rds")

# recycle seeds from SVM model
ctrl$seeds = orig_svm$control$seeds

# run down-sampled model
ctrl$sampling = "down"
ctrl$repeats = 5

timestamp()
down_log = train(artifact ~ .,
                 data = training,
                 method = "LogitBoost",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(down_log, "models/down_log.rds")

# run up-sampled model
ctrl$sampling = "up"
ctrl$repeats = 5

timestamp()
up_rf = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(up_rf, "models/up_rf.rds")

# smote
ctrl$sampling = "smote"
ctrl$repeats = 5

timestamp()
smote_rf = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(smote_rf, "models/smote_rf.rds")

# stop parallelization
stopCluster(cl)
```

### random forest
```{r}
# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial rf
timestamp()
orig_rf_diffs = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(orig_rf_diffs, "models/orig_rf_diffs.rds")

# recycle seeds from SVM model
ctrl$seeds = orig_svm$control$seeds

# run down-sampled model
ctrl$sampling = "down"
ctrl$repeats = 5

timestamp()
down_rf = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(down_rf, "models/down_rf.rds")

# run up-sampled model
ctrl$sampling = "up"
ctrl$repeats = 5

timestamp()
up_rf = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(up_rf, "models/up_rf.rds")

# smote
ctrl$sampling = "smote"
ctrl$repeats = 5

timestamp()
smote_rf = train(artifact ~ .,
                 data = training,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(smote_rf, "models/smote_rf.rds")

# stop parallelization
stopCluster(cl)
```

### gradient boost machine
```{r}
# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial gbm
timestamp()
orig_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(orig_gbm, "models/orig_gbm.rds")

# recycle seeds from SVM model
ctrl$seeds = orig_svm$control$seeds

# run down-sampled model
ctrl$sampling = "down"
ctrl$repeats = 5

timestamp()
down_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(down_gbm, "models/down_gbm.rds")

# run up-sampled model
ctrl$sampling = "up"
ctrl$repeats = 5

timestamp()
up_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(up_gbm, "models/up_gbm.rds")

# smote
ctrl$sampling = "smote"
ctrl$repeats = 5

timestamp()
smote_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(smote_gbm, "models/smote_gbm.rds")

# stop parallelization
stopCluster(cl)
```

### treebag

### gradient boost machine
```{r}
# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial gbm
timestamp()
orig_treebag = train(artifact ~ .,
                 data = training,
                 method = "treebag",
                 nbagg = 50,
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(orig_treebag, "models/orig_treebag.rds")

# recycle seeds from SVM model
ctrl$seeds = orig_svm$control$seeds

# run down-sampled model
ctrl$sampling = "down"
ctrl$repeats = 5

timestamp()
down_treebag = train(artifact ~ .,
                 data = training,
                 method = "treebag",
                 nbagg = 50,
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(down_treebag, "models/down_treebag.rds")

# run up-sampled model
ctrl$sampling = "up"
ctrl$repeats = 5

timestamp()
up_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(up_gbm, "models/up_gbm.rds")

# smote
ctrl$sampling = "smote"
ctrl$repeats = 5

timestamp()
smote_gbm = train(artifact ~ .,
                 data = training,
                 method = "gbm",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(smote_gbm, "models/smote_gbm.rds")

# stop parallelization
stopCluster(cl)
```


## assess models in testing set
```{r}
# define roc function
test_roc <- function(model, data) {
  roc(data$artifact,
      predict(model, data, type = "prob")[, "yes"])
}

# make model lists
model_list = list(SVM = orig_svm, 
                  SVM.up = up_svm, 
                  SVM.down = down_svm,
                  LogReg = orig_log,
                  LogReg.down = down_log,
                  RF = orig_rf,
                  RF.down = down_rf,
                  RF.smote = smote_rf,
                  GBM = orig_gbm,
                  GBM.down = down_gbm,
                  TB = orig_treebag,
                  TB.down = down_treebag)

model_list_roc = model_list %>%
  map(test_roc, data = testing)

# AUC
model_list_roc %>%
  map(auc)

# confusion matrix
confusionMatrix(testing$artifact, predict(orig_svm, testing))
confusionMatrix(testing$artifact, predict(down_svm, testing))
confusionMatrix(testing$artifact, predict(up_svm, testing))

confusionMatrix(testing$artifact, predict(orig_log, testing))
confusionMatrix(testing$artifact, predict(down_log, testing))
#confusionMatrix(testing$artifact, predict(up_log, testing))

confusionMatrix(testing$artifact, predict(orig_rf, testing))
confusionMatrix(testing$artifact, predict(down_rf, testing))
#confusionMatrix(testing$artifact, predict(up_rf, testing))
confusionMatrix(testing$artifact, predict(smote_rf, testing))

confusionMatrix(testing$artifact, predict(orig_gbm, testing))
confusionMatrix(testing$artifact, predict(down_gbm, testing))
#confusionMatrix(testing$artifact, predict(up_rf, testing))

confusionMatrix(testing$artifact, predict(orig_treebag, testing))
confusionMatrix(testing$artifact, predict(down_treebag, testing))
#confusionMatrix(testing$artifact, predict(up_rf, testing))
```

## plot ROC curves
```{r}
results_list_roc = list(NA)
num_mod = 1

for(the_roc in model_list_roc){
  
  results_list_roc[[num_mod]] <- 
    data_frame(TPR = the_roc$sensitivities,
               FPR = 1 - the_roc$specificities,
               Model = names(model_list)[num_mod])
  
  num_mod <- num_mod + 1
  
}

results_df_roc = bind_rows(results_list_roc)

results_df_roc %>% 
  ggplot(aes(FPR, TPR, color = Model)) +
  geom_line(size = .25, alpha = .75) +
  scale_color_manual(values = wesanderson::wes_palette("Darjeeling1", 12, "continuous")) +
  theme_minimal() + 
  geom_abline(intercept = 0, 
              slope = 1, 
              color = "gray37", 
              size = 1)

results_df_roc %>% 
  mutate(model.type = ifelse(grepl("GBM", Model), "GBM",
                      ifelse(grepl("SVM", Model), "SVM",
                      ifelse(grepl("RF", Model), "RF", 
                      ifelse(grepl("LogReg", Model), "LogReg", 
                      ifelse(grepl("TB", Model), "TB", NA)))))) %>%
  ggplot(aes(FPR, TPR, color = Model)) +
  geom_line(size = .25, alpha = .75) +
  scale_color_manual(values = wesanderson::wes_palette("Darjeeling1", 12, "continuous")) +
  facet_grid(~model.type) + 
  theme_minimal() + 
  geom_abline(intercept = 0, 
              slope = 1, 
              color = "gray37", 
              size = 1) 

results_df_roc %>% 
  filter(!grepl("down|up|smote", Model)) %>%
  ggplot(aes(FPR, TPR, color = Model)) +
  geom_line(size = .25, alpha = .75) +
  scale_color_manual(values = wesanderson::wes_palette("Darjeeling1", 6, "continuous")) +
  theme_minimal() + 
  geom_abline(intercept = 0, 
              slope = 1, 
              color = "gray37", 
              size = 1)
```

# Model optimization
```{r}
# load orig_rf model
readRDS("models/orig_rf.rds")

# check variable importance
varImp(orig_rf)

# select top 7 and re-run model
training_red = training %>%
  select(artifact, non.stdDVARS, FramewiseDisplacement, vx.wisestdDVARS, WhiteMatter, stdDVARS, GlobalSignal, CSF)

# turn on parallelization
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# set seed
set.seed(1995)

# set control function
ctrl = trainControl(method = "repeatedcv",
                    number = 10,
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    savePredictions = TRUE,
                    classProbs = TRUE)

# run initial rf
timestamp()
red_rf = train(artifact ~ .,
                 data = training_red,
                 method = "rf",
                 metric = "ROC",
                 trControl = ctrl,  
                 preProcess = c("center","scale"))
timestamp()
saveRDS(red_rf, "models/red_rf.rds")

# define roc function
test_roc <- function(model, data) {
  roc(data$artifact,
      predict(model, data, type = "prob")[, "yes"])
}

# make model lists
model_list = list(RF = orig_rf,
                  RF.red = red_rf)

model_list_roc = model_list %>%
  map(test_roc, data = testing)

# AUC
model_list_roc %>%
  map(auc)

# confusion matrix
confusionMatrix(testing$artifact, predict(orig_rf, testing))
confusionMatrix(testing$artifact, predict(red_rf, testing))

# ROC
results_list_roc = list(NA)
num_mod = 1

for(the_roc in model_list_roc){
  
  results_list_roc[[num_mod]] <- 
    data_frame(TPR = the_roc$sensitivities,
               FPR = 1 - the_roc$specificities,
               spec = the_roc$specificities,
               Model = names(model_list)[num_mod])
  
  num_mod <- num_mod + 1
  
}

results_df_roc = bind_rows(results_list_roc)

results_df_roc %>% 
  ggplot(aes(spec, TPR, color = Model)) +
  geom_line(size = .25, alpha = .75) +
  scale_color_manual(values = wesanderson::wes_palette("Darjeeling1", 12, "continuous")) +
  theme_minimal() + 
  geom_abline(intercept = 0, 
              slope = 1, 
              color = "gray37", 
              size = 1)

# recycle seeds from SVM model
ctrl$seeds = orig_svm$control$seeds
```


# Plot RF predictions/errors
```{r}
# add predictions
plot.train = joined %>%
  mutate(artifact = as.factor(ifelse(artifact == 1, "yes", "no")))
plot.train$predicted = predict(orig_rf, ml.data)

# code predictions
plot.train = plot.train %>%
  mutate(hits = ifelse(artifact == "yes" & predicted == "yes", "hit",
                ifelse(artifact == "no" & predicted == "yes", "false positive",
                ifelse(artifact == "yes" & predicted == "no", "false negative", NA))),
         label = ifelse(regexpr('.*', hits), as.character(volume), ''),
         hits = as.factor(hits))

nada = plot.train %>% 
  group_by(subjectID, task, run) %>%
    do({
      plot = ggplot(plot.train, aes(x = volume, y = FramewiseDisplacement)) +
        geom_line(data = filter(plot.train, subjectID == .$subjectID[[1]] & task == .$task[[1]] & run == .$run[[1]]), size = .25) +
        geom_point(data = subset(filter(plot.train, subjectID == .$subjectID[[1]] & task == .$task[[1]] & run == .$run[[1]]), !is.na(hits)), aes(color = hits), size = 2.5) +
        geom_text(data = filter(plot.train, subjectID == .$subjectID[[1]] & task == .$task[[1]] & run == .$run[[1]]), aes(label = label), size = 1.5) +
        scale_color_manual(values = c(hit = "#3B9AB2", `false negative` = "#EBCC2A", `false positive` = "#F21A00")) +
        labs(title = paste0(.$subjectID[[1]], "  ", .$task[[1]], "  ", .$run[[1]])) +
        theme_minimal() +
        theme(axis.text.x = element_text(size = 6),
              legend.position = "top", 
              #legend.justification = c(1, 1),
              legend.direction = "horizontal",
              legend.title = element_blank())
      print(plot)
      ggsave(plot, file = paste0(plotDir,'predicted/',.$subjectID[[1]],"_",.$task[[1]],"_",.$run[[1]],'.png'), height = 4, width = 6)
      data.frame()
    })

ggplot(plot.train, aes(x = volume, y = FramewiseDisplacement)) +
        geom_line(size = .25) +
        geom_point(data = subset(plot.train, !is.na(hits)), aes(color = hits), size = 2.5) +
        geom_text(aes(label = label), size = 1.5) +
        scale_color_manual(values = c("#3B9AB2","#EBCC2A","#F21A00")) +
        theme(axis.text.x = element_text(size = 6)) +
        #labs(title = paste0(.$subjectID[[1]], "  ", .$task[[1]], "  ", .$run[[1]])) +
        theme_minimal()
```